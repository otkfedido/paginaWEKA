<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by TEMPLATED
http://templated.co
Released for free under the Creative Commons Attribution License

Name       : Justifiable 
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20130801

-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title></title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="http://fonts.googleapis.com/css?family=Open+Sans:400,300,600,700,800|Open+Sans+Condensed:300,700" rel="stylesheet" />
<link href="default.css" rel="stylesheet" type="text/css" media="all" />
<link href="fonts.css" rel="stylesheet" type="text/css" media="all" />

<!--[if IE 6]><link href="default_ie6.css" rel="stylesheet" type="text/css" /><![endif]-->

</head>
<body>
<div id="logo" class="container">
    <h1><a href="#"><span>Weka</span></a></h1>
	<p>Tudo sobre:</p>
	<img src="imagens/weka.png" alt=""></a> </div>
</div>
<div id="wrapper" class="container">
	<div id="menu" class="container">
		<ul>
			<li><a href="historia.html" accesskey="1" title="">Historia</a></li>
			<li><a href="paginaInstalação.html" accesskey="1" title="">Instalação</a></li>
			<li><a href="pagina.arff.html" accesskey="2" title="">Arquivo .arff</a></li>
			<li><a href="CSV.html" accesskey="3" title="">CSV</a></li>
			<li class="current_page_item"><a href="KNN.html" accesskey="4" title="">KNN</a></li>
		</ul>
	</div>
	
	<div id="page">
		<br>
		<div class="title">
		<h2>Introdução ao KNN</h2>
		</div>
		<br>
		<p>O algoritmo KNN (K Nearest Neighbor) é um dos algoritmos mais utilizados em Machine Learning e 
			também um dos mais simplistas, analisando seu processo de cálculo. Este algoritmo pode ser 
			aplicado em diversos segmentos de negócio, logo também se aplica em diversos problemas como 
			finanças, saúde, ciência política, reconhecimento de imagem e reconhecimento de vídeos.
			O que acho mais fantástico neste algoritmo é a possibilidade de utilização do mesmo tanto para 
			classificação quanto para regressão. Na classificação a máquina irá dizer a que grupo determinado
			registro faz parte, dentro obviamente de um contexto de negócio. Já a regressão irá nos fornecer
			um número/valor, por exemplo o valor de mercado de uma determinada casa que irá ser colocada a 
			venda. Para ambos os casos o algoritmo irá analisar diversas features (Colunas com dados, as
			 quais geraram informação).</p>
	<br>
	<br>
	<div class="title">
		<h2>Oque é o KNN:</h2>
		</div>
		<br>
		<p>O KNN é um algoritmo não paramétrico, aonde a estrutura do modelo será determinada pelo dataset 
			utilizado. Este algoritmo também é conhecido como de aprendizado lento ou melhor dizendo, é um 
			algoritmo preguiçoso, o termo certo é “lazy”. Os algoritmos do tipo lazy, não necessitam de 
			dados de treinamento para se gerar o modelo, o que diminui em partes o processo inicial, 
			mas em contrapartida gerará uma necessidade de análise posterior mais apurada. No caso de 
			algoritmos que não necessitam de treinamento, todos os dados obtidos no dataset serão utilizados 
			na fase de teste, resultando em um treinamento muito rápido e em um teste e validação lentos,
			momento o qual necessitamos estar bem atentos aos resultados gerados.</p>

	<br>
	<br>
	<div class="title">
		<h2>Como o KNN (K Nearest Neighbor) Funciona:</h2>
		</div>
		<br>
		<p>Neste algoritmo possuímos uma variável chamada de K, a qual é parte do nome do modelo e 
		também o principal parâmetro a ser selecionado. Este parâmetro direcionará a quantidade 
		de vizinhos (neighborn em inglês). Em casos de modelos binários, aonde possuímos apenas duas 
		classes, em geral aplicasse valores ímpares a K, mas lembre-se que cada caso é um caso, “No free 
		lunch”. Imagine que temos um valor P1 o qual queremos predizer, entre um grupo de duas classes 
		aonde o valor atribuído a K foi 1 (K=1), primeiro iremos identificar o ponto mais próximo a ele 
		e depois qual a label que o identifica (classe A por exemplo)</p>
		<img src="imagens/KNN 1.png" alt=""></a> 
		<br>
		<p>Após identificar o ponto mais próximo e identificar a label deste ponto (Ex.: Classe A), 
		iremos predizer a que classe o ponto P1 faz parte. Para identificar de fato a que grupo o 
		ponto P1 faz parte, iremos realizar uma votação aonde a maioria irá dizer a que classe este 
		ponto P1 realmente faz parte.</p>
	<br>
	<br>
	<div class="title">
		<h2>O passos que o algoritimo utiliza: </h2>
	</div>
		<br>
		<p> 1) Calcular a distância; <br>
			2) Encontrar os pontos/vizinhos mais próximos; <br>
			3) Votar a label para o ponto a ser previsto; <br>
		</p>
	</div>
	<div id="three-column" class="container">
		<div><span class=""></span></div>
		<div id="tbox1"> <span class=""></span>
			<p><img src="imagens/KNN c1.png" alt=""></a> </p>
		</div>
		<div id="tbox2"> <span class=""></span>	
			<p><img src="imagens/KNN c2.png" alt=""></a> </p>
			</div>
		<div id="tbox3"> <span class=""></span>
			<p><img src="imagens/KNN c3.png" alt=""></a> </p>
		</div>
			

	</div>
	<div id="page">
			<div class="title">
				<h2>Como avaliar o KNN</h2></div>
			<p>A KNN faz previsões usando o conjunto de dados de treinamento diretamente
				As previsões são feitas para uma nova instância (x) pesquisando todo o conjunto de
				treinamento para as K instâncias mais semelhantes (os vizinhos) e resumindo a variável 
				de saída para essas instâncias de K. Para a regressão, essa pode ser a variável de saída
				 média; na classificação, esse pode ser o valor de classe do modo (ou mais comum).
				Para determinar quais das instâncias do K no conjunto de dados de treinamento são mais 
				semelhantes a uma nova entrada, uma medida de distância é usada. Para variáveis ​​de entrada 
				de valor real, a medida de distância mais popular é a distância euclidiana.
				A distância euclidiana é calculada como a raiz quadrada da soma das diferenças quadráticas 
				entre um novo ponto (x) e um ponto existente (xi) em todos os atributos de entrada j.</p>
				 <br>
				 <h2>Distância Euclidiana (x, xi) = sqrt (soma ((xj – xij) ^ 2)).</h2>
		
		
			<div class="title">
				<h2>Para que serve o KNN:</h2>
				</div>
			<p>O KNN pode ser usado para problemas de regressão e classificação. Porem 
				a ideia principal do KNN é determinar o rótulo de classificação de uma 
				amostra baseado nas amostras vizinhas advindas de um conjunto de treinamento.</p>	
	</div>
</div>
<div id="copyright">
	<p>&copy; Obrigado por ler. | Feito por Joao Pedro Mussalam. | Para a materia de Implantação de sistemas. </p>
</div>
</body>
</html>
